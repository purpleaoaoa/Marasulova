{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6RnwL0yZ6uEL60Vl60pQv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purpleaoaoa/Marasulova/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import utils\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import models\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image \n",
        "%matplotlib inline\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "x_train = x_train.reshape(60000, 784) \n",
        "x_test = x_test.reshape(10000, 784) \n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "y_train = utils.to_categorical(y_train, 10)\n",
        "y_test = utils.to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(800, input_dim = 784, activation = \"relu\"))\n",
        "model.add(Dense(10 , activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"SGD\", metrics = [\"accuracy\"])\n",
        "print(model.summary())\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size = 200, \n",
        "                    epochs = 100, \n",
        "                    validation_split = 0.2,\n",
        "                    verbose = 1)\n",
        "model.save('mnist_dense.h5')\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose = 1)\n",
        "print(\"Доля верных ответов на тестовых данных, в процентах: \", round(scores[1] * 100, 4))\n",
        "\n",
        "#model = models.load_model('mnist_dense.h5')\n",
        "\n",
        "n_rec = 4889\n",
        "plt.imshow(x_test[n_rec].reshape(28, 28), cmap = plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "x = x_test[n_rec]\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "prediction = model.predict(x)\n",
        "prediction = np.argmax(prediction[0])\n",
        "print(\"Цифра: \", prediction)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xD3TXEorMIXb",
        "outputId": "58ab2bf3-f103-47f2-c854-65e3c1782d7f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 800)               628000    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                8010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 636,010\n",
            "Trainable params: 636,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 1.4224 - accuracy: 0.6914 - val_loss: 0.8702 - val_accuracy: 0.8422\n",
            "Epoch 2/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.7268 - accuracy: 0.8475 - val_loss: 0.5750 - val_accuracy: 0.8733\n",
            "Epoch 3/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5502 - accuracy: 0.8703 - val_loss: 0.4709 - val_accuracy: 0.8867\n",
            "Epoch 4/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4730 - accuracy: 0.8813 - val_loss: 0.4175 - val_accuracy: 0.8953\n",
            "Epoch 5/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4284 - accuracy: 0.8895 - val_loss: 0.3851 - val_accuracy: 0.8996\n",
            "Epoch 6/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.3988 - accuracy: 0.8947 - val_loss: 0.3622 - val_accuracy: 0.9038\n",
            "Epoch 7/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.3772 - accuracy: 0.8986 - val_loss: 0.3461 - val_accuracy: 0.9056\n",
            "Epoch 8/100\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.3603 - accuracy: 0.9022 - val_loss: 0.3322 - val_accuracy: 0.9097\n",
            "Epoch 9/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.3466 - accuracy: 0.9059 - val_loss: 0.3216 - val_accuracy: 0.9103\n",
            "Epoch 10/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.3351 - accuracy: 0.9084 - val_loss: 0.3119 - val_accuracy: 0.9143\n",
            "Epoch 11/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.3252 - accuracy: 0.9107 - val_loss: 0.3042 - val_accuracy: 0.9152\n",
            "Epoch 12/100\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.3164 - accuracy: 0.9126 - val_loss: 0.2965 - val_accuracy: 0.9178\n",
            "Epoch 13/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.3084 - accuracy: 0.9149 - val_loss: 0.2904 - val_accuracy: 0.9185\n",
            "Epoch 14/100\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.3013 - accuracy: 0.9168 - val_loss: 0.2840 - val_accuracy: 0.9204\n",
            "Epoch 15/100\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.2949 - accuracy: 0.9183 - val_loss: 0.2786 - val_accuracy: 0.9219\n",
            "Epoch 16/100\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.2887 - accuracy: 0.9201 - val_loss: 0.2735 - val_accuracy: 0.9227\n",
            "Epoch 17/100\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.2829 - accuracy: 0.9215 - val_loss: 0.2690 - val_accuracy: 0.9247\n",
            "Epoch 18/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.2778 - accuracy: 0.9231 - val_loss: 0.2645 - val_accuracy: 0.9266\n",
            "Epoch 19/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.2727 - accuracy: 0.9249 - val_loss: 0.2601 - val_accuracy: 0.9269\n",
            "Epoch 20/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.2679 - accuracy: 0.9254 - val_loss: 0.2560 - val_accuracy: 0.9280\n",
            "Epoch 21/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.2634 - accuracy: 0.9267 - val_loss: 0.2525 - val_accuracy: 0.9289\n",
            "Epoch 22/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.2590 - accuracy: 0.9281 - val_loss: 0.2488 - val_accuracy: 0.9308\n",
            "Epoch 23/100\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.2548 - accuracy: 0.9297 - val_loss: 0.2452 - val_accuracy: 0.9311\n",
            "Epoch 24/100\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.2509 - accuracy: 0.9304 - val_loss: 0.2416 - val_accuracy: 0.9323\n",
            "Epoch 25/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.2469 - accuracy: 0.9322 - val_loss: 0.2386 - val_accuracy: 0.9335\n",
            "Epoch 26/100\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.2434 - accuracy: 0.9325 - val_loss: 0.2352 - val_accuracy: 0.9338\n",
            "Epoch 27/100\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.2398 - accuracy: 0.9338 - val_loss: 0.2323 - val_accuracy: 0.9350\n",
            "Epoch 28/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.2363 - accuracy: 0.9347 - val_loss: 0.2295 - val_accuracy: 0.9355\n",
            "Epoch 29/100\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.2330 - accuracy: 0.9355 - val_loss: 0.2264 - val_accuracy: 0.9365\n",
            "Epoch 30/100\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.2297 - accuracy: 0.9364 - val_loss: 0.2238 - val_accuracy: 0.9377\n",
            "Epoch 31/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.2266 - accuracy: 0.9371 - val_loss: 0.2210 - val_accuracy: 0.9383\n",
            "Epoch 32/100\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.2235 - accuracy: 0.9385 - val_loss: 0.2187 - val_accuracy: 0.9394\n",
            "Epoch 33/100\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.2206 - accuracy: 0.9388 - val_loss: 0.2158 - val_accuracy: 0.9402\n",
            "Epoch 34/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.2177 - accuracy: 0.9398 - val_loss: 0.2134 - val_accuracy: 0.9408\n",
            "Epoch 35/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.2149 - accuracy: 0.9403 - val_loss: 0.2110 - val_accuracy: 0.9422\n",
            "Epoch 36/100\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.2122 - accuracy: 0.9412 - val_loss: 0.2087 - val_accuracy: 0.9424\n",
            "Epoch 37/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.2095 - accuracy: 0.9416 - val_loss: 0.2066 - val_accuracy: 0.9430\n",
            "Epoch 38/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.2070 - accuracy: 0.9421 - val_loss: 0.2044 - val_accuracy: 0.9441\n",
            "Epoch 39/100\n",
            "240/240 [==============================] - 5s 21ms/step - loss: 0.2044 - accuracy: 0.9432 - val_loss: 0.2027 - val_accuracy: 0.9451\n",
            "Epoch 40/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.2019 - accuracy: 0.9440 - val_loss: 0.2004 - val_accuracy: 0.9453\n",
            "Epoch 41/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1995 - accuracy: 0.9444 - val_loss: 0.1979 - val_accuracy: 0.9455\n",
            "Epoch 42/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1972 - accuracy: 0.9454 - val_loss: 0.1962 - val_accuracy: 0.9461\n",
            "Epoch 43/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1948 - accuracy: 0.9463 - val_loss: 0.1945 - val_accuracy: 0.9476\n",
            "Epoch 44/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1926 - accuracy: 0.9467 - val_loss: 0.1928 - val_accuracy: 0.9479\n",
            "Epoch 45/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1904 - accuracy: 0.9473 - val_loss: 0.1906 - val_accuracy: 0.9486\n",
            "Epoch 46/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1882 - accuracy: 0.9476 - val_loss: 0.1888 - val_accuracy: 0.9492\n",
            "Epoch 47/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1862 - accuracy: 0.9484 - val_loss: 0.1871 - val_accuracy: 0.9498\n",
            "Epoch 48/100\n",
            "240/240 [==============================] - 5s 21ms/step - loss: 0.1841 - accuracy: 0.9487 - val_loss: 0.1854 - val_accuracy: 0.9498\n",
            "Epoch 49/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1821 - accuracy: 0.9494 - val_loss: 0.1837 - val_accuracy: 0.9505\n",
            "Epoch 50/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1802 - accuracy: 0.9499 - val_loss: 0.1822 - val_accuracy: 0.9507\n",
            "Epoch 51/100\n",
            "240/240 [==============================] - 5s 21ms/step - loss: 0.1781 - accuracy: 0.9502 - val_loss: 0.1807 - val_accuracy: 0.9512\n",
            "Epoch 52/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1762 - accuracy: 0.9511 - val_loss: 0.1790 - val_accuracy: 0.9510\n",
            "Epoch 53/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1743 - accuracy: 0.9514 - val_loss: 0.1776 - val_accuracy: 0.9519\n",
            "Epoch 54/100\n",
            "240/240 [==============================] - 5s 21ms/step - loss: 0.1727 - accuracy: 0.9520 - val_loss: 0.1761 - val_accuracy: 0.9517\n",
            "Epoch 55/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1708 - accuracy: 0.9523 - val_loss: 0.1747 - val_accuracy: 0.9527\n",
            "Epoch 56/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.1690 - accuracy: 0.9532 - val_loss: 0.1730 - val_accuracy: 0.9528\n",
            "Epoch 57/100\n",
            "240/240 [==============================] - 5s 21ms/step - loss: 0.1674 - accuracy: 0.9538 - val_loss: 0.1715 - val_accuracy: 0.9532\n",
            "Epoch 58/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1656 - accuracy: 0.9538 - val_loss: 0.1704 - val_accuracy: 0.9530\n",
            "Epoch 59/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1640 - accuracy: 0.9547 - val_loss: 0.1689 - val_accuracy: 0.9543\n",
            "Epoch 60/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1624 - accuracy: 0.9550 - val_loss: 0.1676 - val_accuracy: 0.9545\n",
            "Epoch 61/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1607 - accuracy: 0.9553 - val_loss: 0.1664 - val_accuracy: 0.9543\n",
            "Epoch 62/100\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.1593 - accuracy: 0.9558 - val_loss: 0.1651 - val_accuracy: 0.9551\n",
            "Epoch 63/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1577 - accuracy: 0.9563 - val_loss: 0.1638 - val_accuracy: 0.9556\n",
            "Epoch 64/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.1561 - accuracy: 0.9569 - val_loss: 0.1631 - val_accuracy: 0.9562\n",
            "Epoch 65/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1546 - accuracy: 0.9570 - val_loss: 0.1615 - val_accuracy: 0.9556\n",
            "Epoch 66/100\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.1531 - accuracy: 0.9576 - val_loss: 0.1604 - val_accuracy: 0.9565\n",
            "Epoch 67/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.1518 - accuracy: 0.9579 - val_loss: 0.1591 - val_accuracy: 0.9567\n",
            "Epoch 68/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1504 - accuracy: 0.9583 - val_loss: 0.1579 - val_accuracy: 0.9570\n",
            "Epoch 69/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1490 - accuracy: 0.9588 - val_loss: 0.1569 - val_accuracy: 0.9576\n",
            "Epoch 70/100\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.1477 - accuracy: 0.9591 - val_loss: 0.1559 - val_accuracy: 0.9578\n",
            "Epoch 71/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1464 - accuracy: 0.9596 - val_loss: 0.1549 - val_accuracy: 0.9582\n",
            "Epoch 72/100\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.1451 - accuracy: 0.9596 - val_loss: 0.1539 - val_accuracy: 0.9587\n",
            "Epoch 73/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1437 - accuracy: 0.9602 - val_loss: 0.1528 - val_accuracy: 0.9585\n",
            "Epoch 74/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1425 - accuracy: 0.9607 - val_loss: 0.1517 - val_accuracy: 0.9589\n",
            "Epoch 75/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1413 - accuracy: 0.9610 - val_loss: 0.1507 - val_accuracy: 0.9597\n",
            "Epoch 76/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1400 - accuracy: 0.9615 - val_loss: 0.1501 - val_accuracy: 0.9593\n",
            "Epoch 77/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1388 - accuracy: 0.9620 - val_loss: 0.1491 - val_accuracy: 0.9597\n",
            "Epoch 78/100\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 0.1377 - accuracy: 0.9621 - val_loss: 0.1482 - val_accuracy: 0.9596\n",
            "Epoch 79/100\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.1365 - accuracy: 0.9624 - val_loss: 0.1477 - val_accuracy: 0.9601\n",
            "Epoch 80/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1354 - accuracy: 0.9629 - val_loss: 0.1462 - val_accuracy: 0.9605\n",
            "Epoch 81/100\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.1342 - accuracy: 0.9632 - val_loss: 0.1452 - val_accuracy: 0.9606\n",
            "Epoch 82/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1331 - accuracy: 0.9635 - val_loss: 0.1445 - val_accuracy: 0.9610\n",
            "Epoch 83/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.1320 - accuracy: 0.9636 - val_loss: 0.1438 - val_accuracy: 0.9611\n",
            "Epoch 84/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1309 - accuracy: 0.9644 - val_loss: 0.1430 - val_accuracy: 0.9612\n",
            "Epoch 85/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1299 - accuracy: 0.9647 - val_loss: 0.1420 - val_accuracy: 0.9613\n",
            "Epoch 86/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.1289 - accuracy: 0.9651 - val_loss: 0.1412 - val_accuracy: 0.9620\n",
            "Epoch 87/100\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.1278 - accuracy: 0.9653 - val_loss: 0.1404 - val_accuracy: 0.9621\n",
            "Epoch 88/100\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.1268 - accuracy: 0.9656 - val_loss: 0.1399 - val_accuracy: 0.9620\n",
            "Epoch 89/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1258 - accuracy: 0.9659 - val_loss: 0.1390 - val_accuracy: 0.9622\n",
            "Epoch 90/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1248 - accuracy: 0.9666 - val_loss: 0.1382 - val_accuracy: 0.9629\n",
            "Epoch 91/100\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.1239 - accuracy: 0.9668 - val_loss: 0.1376 - val_accuracy: 0.9620\n",
            "Epoch 92/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1229 - accuracy: 0.9669 - val_loss: 0.1368 - val_accuracy: 0.9622\n",
            "Epoch 93/100\n",
            "240/240 [==============================] - 4s 19ms/step - loss: 0.1220 - accuracy: 0.9671 - val_loss: 0.1359 - val_accuracy: 0.9629\n",
            "Epoch 94/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1211 - accuracy: 0.9674 - val_loss: 0.1354 - val_accuracy: 0.9630\n",
            "Epoch 95/100\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.1202 - accuracy: 0.9677 - val_loss: 0.1347 - val_accuracy: 0.9630\n",
            "Epoch 96/100\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.1192 - accuracy: 0.9680 - val_loss: 0.1343 - val_accuracy: 0.9633\n",
            "Epoch 97/100\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.1184 - accuracy: 0.9684 - val_loss: 0.1336 - val_accuracy: 0.9632\n",
            "Epoch 98/100\n",
            "240/240 [==============================] - 4s 15ms/step - loss: 0.1175 - accuracy: 0.9686 - val_loss: 0.1327 - val_accuracy: 0.9632\n",
            "Epoch 99/100\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.1166 - accuracy: 0.9689 - val_loss: 0.1321 - val_accuracy: 0.9632\n",
            "Epoch 100/100\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.1158 - accuracy: 0.9691 - val_loss: 0.1316 - val_accuracy: 0.9640\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1265 - accuracy: 0.9630\n",
            "Доля верных ответов на тестовых данных, в процентах:  96.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n",
            "Цифра:  2\n"
          ]
        }
      ]
    }
  ]
}